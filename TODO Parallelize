##Kapitel 1: Zeit-Gliederung für Code (mit profvis) -> begründung wieso wir einen teil verbessert haben
##Kapitel 2: Vergleich Datensatz vor und nach Preprocessing (e.g. char -> int umwandlung)(mem_change(), mem_used(),compare_size())
Kapitel 2: Hyperparameter bei algo (zb RF) anpassen, und über runtime-accuracy trade-off reden (runtime zwischen beiden auf sample datensatz)
##Kapitel 2: Einen algo in Spark implementieren -> vergleich
##Kapitel 3: Einen algo parallelisieren -> vergleich
##Kapitel 4: Datatypes im Datensatz aufzeigen und veränderung (siehe Kapitel 2)
##Kapitel 4: Plot runtime vs %-dataset -> exponential, oder linear?
Kapitel 4: memory der verschiedenen data types analysieren. str() für gute übersicht nutzen.
Kapitel 5: ff package implementieren + vgl mit normalem


# TODO
1. (maro) Skipte Zusammenfügen
2. (maro) Scaling in Preprocessing skript
3. (stef) ProfVis über die skripte jeweils

----
4. (maro) Vergleich Datensatz vor und nach Preprocessing (e.g. char -> int umwandlung)(einfluss der data types)(mem_change(), mem_used(),compare_size())
5. (maro) Algorithmen mit längster laufzeit parallelisieren.
6. (stef) Algorithmen mit längster laufzeit in spark implementieren.

----
7. (stef) Plot runtime vs %-dataset -> exponential, oder linear?
8. RF Hyperparameter impact analysieren
9. ff package implementieren + vgl mit normalem